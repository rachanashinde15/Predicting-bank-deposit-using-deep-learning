{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResnetCiphar100.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOuVf6gGOVdumM4iU/NUmaU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rachanashinde15/Predicting-bank-deposit-using-deep-learning/blob/main/ResnetCiphar100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AF-fFZuQpojJ"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation, Dropout\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar100\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ],
      "metadata": {
        "id": "tFh7SKPtrJph"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 100\n",
        "num_classes = 100\n",
        "depth = 20\n",
        "subtract_pixel_mean = True"
      ],
      "metadata": {
        "id": "ofVEU0BMrM7m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_type = 'ResNet%d' % (depth)"
      ],
      "metadata": {
        "id": "FJz7hcsIrtJ0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wVKEcCXrvuB",
        "outputId": "ef615e16-3ace-4bfe-bf1c-2db4a8d345a6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 6s 0us/step\n",
            "169017344/169001437 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "input_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv8QwUekrzzF",
        "outputId": "3c66965e-0777-4011-e6ec-5726d007c413"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "metadata": {
        "id": "VTeetYmgr20H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if subtract_pixel_mean:\n",
        "  x_train_mean = np.mean(x_train, axis=0)\n",
        "  x_train -= x_train_mean\n",
        "  x_test -= x_train_mean"
      ],
      "metadata": {
        "id": "XpnTg41sr5UQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_train shape:', x_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcAuQS3gr7-u",
        "outputId": "dc598dd8-a459-40cb-881f-af27f7d1f2ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "pElUNR21r_hF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_schedule(epoch):\n",
        "  lr = 1e-3\n",
        "  if epoch > 180:\n",
        "      lr *= 0.5e-3\n",
        "  elif epoch > 160:\n",
        "      lr *= 1e-3\n",
        "  elif epoch > 120:\n",
        "      lr *= 1e-2\n",
        "  elif epoch > 80:\n",
        "      lr *= 1e-1\n",
        "  print('Learning rate: ', lr)\n",
        "  return lr"
      ],
      "metadata": {
        "id": "-t1Xp120sj_T"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet_layer(inputs, num_filters=16, kernel_size=3, strides=1, activation='relu', batch_normalization=True, conv_first=True):\n",
        "  \n",
        "  conv = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')\n",
        "\n",
        "  x = inputs\n",
        "  if conv_first:\n",
        "      x = conv(x)\n",
        "      if batch_normalization:\n",
        "          x = BatchNormalization()(x)\n",
        "      if activation is not None:\n",
        "          x = Activation(activation)(x)\n",
        "  else:\n",
        "      if batch_normalization:\n",
        "          x = BatchNormalization()(x)\n",
        "      if activation is not None:\n",
        "          x = Activation(activation)(x)\n",
        "      x = conv(x)\n",
        "  return x"
      ],
      "metadata": {
        "id": "87SnclQjsmYO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=100):\n",
        "    \n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,num_filters=num_filters,strides=strides)\n",
        "            y = resnet_layer(inputs=y,num_filters=num_filters,activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,num_filters=num_filters,kernel_size=1,strides=strides,activation=None,batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "            x = Dropout(rate=0.25)(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "uJlvLWH6srKm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet_v1(input_shape=input_shape, depth=depth)"
      ],
      "metadata": {
        "id": "EzIpPY8nsv_Y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=lr_schedule(0)),metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2Xrqc1bszAq",
        "outputId": "df23d913-9596-4e39-806a-694f3aca9ef0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate:  0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "print(model_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfuXFhbFs128",
        "outputId": "5383ca56-8cfe-4f4d-d233-761660f6c6fa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 32, 32, 16)   448         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 32, 32, 16)  64          ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 32, 32, 16)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 32, 32, 16)   2320        ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 32, 32, 16)   0           ['activation[0][0]',             \n",
            "                                                                  'batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 32, 32, 16)   0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 32, 32, 16)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 32, 32, 16)   2320        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 32, 32, 16)   0           ['dropout[0][0]',                \n",
            "                                                                  'batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 32, 32, 16)   0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 32, 32, 16)   0           ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 32, 32, 16)   2320        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 32, 32, 16)   0           ['dropout_1[0][0]',              \n",
            "                                                                  'batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 32, 32, 16)   0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 32, 32, 16)   0           ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 32)   4640        ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 32)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 32)   9248        ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 32)   544         ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 16, 16, 32)   0           ['conv2d_9[0][0]',               \n",
            "                                                                  'batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 32)   0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 16, 16, 32)   0           ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 32)   9248        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_10[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 32)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 32)  128         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 16, 16, 32)   0           ['dropout_3[0][0]',              \n",
            "                                                                  'batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 16, 16, 32)   0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 16, 16, 32)   0           ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 32)   9248        ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 32)  128         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 32)  128         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 16, 16, 32)   0           ['dropout_4[0][0]',              \n",
            "                                                                  'batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 32)   0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 16, 16, 32)   0           ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 8, 8, 64)     18496       ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 8, 8, 64)    256         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 8, 8, 64)     2112        ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 8, 8, 64)    256         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 8, 8, 64)     0           ['conv2d_16[0][0]',              \n",
            "                                                                  'batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 8, 8, 64)     0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 8, 8, 64)     0           ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 8, 8, 64)     36928       ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 8, 8, 64)    256         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 8, 8, 64)    256         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 8, 8, 64)     0           ['dropout_6[0][0]',              \n",
            "                                                                  'batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 8, 8, 64)     0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 8, 8, 64)     0           ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 8, 8, 64)     36928       ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 8, 8, 64)    256         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 8, 8, 64)    256         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 8, 8, 64)     0           ['dropout_7[0][0]',              \n",
            "                                                                  'batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 8, 8, 64)     0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 8, 8, 64)     0           ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 1, 1, 64)    0           ['dropout_8[0][0]']              \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 64)           0           ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 100)          6500        ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 280,292\n",
            "Trainable params: 278,916\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = os.path.join(os.getcwd(), 'saved_models_with_dropout')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)"
      ],
      "metadata": {
        "id": "CiKE_ebrs5cv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(filepath=filepath,monitor='val_acc',verbose=1,save_best_only=True)"
      ],
      "metadata": {
        "id": "eIUPPED9s8zV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_scheduler = LearningRateScheduler(lr_schedule)"
      ],
      "metadata": {
        "id": "H5IXaw4Us_lh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [checkpoint, lr_scheduler]"
      ],
      "metadata": {
        "id": "KyO7JAsJtDTE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,validation_data=(x_test, y_test),shuffle=True,callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhU1JtWZtGLa",
        "outputId": "ed7229cc-b0eb-4564-c6da-69ec99d49625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate:  0.001\n",
            "Epoch 1/100\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 4.0401 - accuracy: 0.0761WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 563s 359ms/step - loss: 4.0401 - accuracy: 0.0761 - val_loss: 3.9078 - val_accuracy: 0.1029 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 3.5334 - accuracy: 0.1506WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 548s 351ms/step - loss: 3.5334 - accuracy: 0.1506 - val_loss: 3.6843 - val_accuracy: 0.1409 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 3.1975 - accuracy: 0.2080WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 548s 351ms/step - loss: 3.1975 - accuracy: 0.2080 - val_loss: 3.2511 - val_accuracy: 0.2057 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 2.9662 - accuracy: 0.2517WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 559s 358ms/step - loss: 2.9662 - accuracy: 0.2517 - val_loss: 2.9208 - val_accuracy: 0.2557 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 2.7977 - accuracy: 0.2831WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 572s 366ms/step - loss: 2.7977 - accuracy: 0.2831 - val_loss: 2.9669 - val_accuracy: 0.2590 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 2.6643 - accuracy: 0.3118WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 536s 343ms/step - loss: 2.6643 - accuracy: 0.3118 - val_loss: 2.5937 - val_accuracy: 0.3255 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 2.5602 - accuracy: 0.3319WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 684s 438ms/step - loss: 2.5602 - accuracy: 0.3319 - val_loss: 2.5782 - val_accuracy: 0.3310 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 2.4675 - accuracy: 0.3532WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 536s 343ms/step - loss: 2.4675 - accuracy: 0.3532 - val_loss: 2.3706 - val_accuracy: 0.3757 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 2.4021 - accuracy: 0.3646WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 546s 349ms/step - loss: 2.4021 - accuracy: 0.3646 - val_loss: 2.3841 - val_accuracy: 0.3694 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 2.3347 - accuracy: 0.3779WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 557s 357ms/step - loss: 2.3347 - accuracy: 0.3779 - val_loss: 2.5364 - val_accuracy: 0.3510 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 11/100\n",
            " 191/1563 [==>...........................] - ETA: 7:50 - loss: 2.2542 - accuracy: 0.3971"
          ]
        }
      ]
    }
  ]
}